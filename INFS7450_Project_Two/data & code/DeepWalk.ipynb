{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from random import choice, choices\n",
    "import gensim\n",
    "from math import sqrt\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "\n",
    "def readData(filename):\n",
    "    data = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "         data.append(line.strip().split())\n",
    "    return data\n",
    "\n",
    "def evaluation(topList, groundTruth):\n",
    "    count = 0\n",
    "    for link in topList:\n",
    "        if link[0] in groundTruth:\n",
    "            count += 1\n",
    "    print(float(count) / len(groundTruth) * 100, '%')\n",
    "\n",
    "def buildGraph(data):\n",
    "    G = nx.Graph()\n",
    "    for pair in data:\n",
    "        G.add_edge(pair[0],pair[1])\n",
    "    return G\n",
    "\n",
    "def get_bias(b_centralities, neighbors):\n",
    "    bias = []\n",
    "    for node in neighbors:\n",
    "        bias.append(b_centralities[node])\n",
    "    return bias\n",
    "\n",
    "def randomWalk(G,length,strategy, B):\n",
    "    if strategy == 'bfs&dfs':\n",
    "        walks = []\n",
    "        #length = 4\n",
    "        print('Generating dfs&bfs mixed random walks...')\n",
    "        for i in range(20):\n",
    "            #repeat 20 times to collect more walks for each node\n",
    "            for node in G.nodes:\n",
    "                #start the random walk with each node as the starter\n",
    "                walk = [node]\n",
    "                walkLength = 0\n",
    "                while walkLength<length:\n",
    "                    node = choice(list(G.neighbors(node)))\n",
    "                    walk.append(node)\n",
    "                    node = list(G.neighbors(node))[0]\n",
    "                    walk.append(node)\n",
    "                    walkLength += 1\n",
    "                walks.append(walk)\n",
    "        return walks\n",
    "    elif strategy == 'bias':\n",
    "        print('Generating betweeness centralities...')\n",
    "        #length = 23\n",
    "        b_centralities = B\n",
    "    walks = []\n",
    "    print('Generating random walks...')\n",
    "    for i in range(5):\n",
    "        #repeat 5 times to collect more walks for each node\n",
    "        for node in G.nodes:\n",
    "            #start the random walk with each node as the starter\n",
    "            walk = [node]\n",
    "            walkLength = 0\n",
    "            while walkLength<length:\n",
    "                if strategy == 'random':\n",
    "                    node = choice(list(G.neighbors(node)))\n",
    "                elif strategy == 'bias':\n",
    "                    neighbors = list(G.neighbors(node))\n",
    "                    biases = get_bias(b_centralities, neighbors)\n",
    "                    node = choices(neighbors, biases)[0]\n",
    "                walk.append(node)\n",
    "                walkLength += 1\n",
    "            walks.append(walk)\n",
    "    return walks\n",
    "\n",
    "def skipGram(walks, method):\n",
    "    print('Training Skip-Gram model... Pleas wait.')\n",
    "    #using Skip-Gram\n",
    "    if method == 'bfs&dfs':\n",
    "        model = gensim.models.Word2Vec(walks,window=8,sg=1)\n",
    "    elif method == 'bias':\n",
    "        model = gensim.models.Word2Vec(walks,window=8,sg=4)\n",
    "    elif method == 'random':\n",
    "        model = gensim.models.Word2Vec(walks,window=5,sg=1)\n",
    "    return model\n",
    "\n",
    "def computeProximityScore(em1,em2):\n",
    "    #Cosine Similarity\n",
    "    score = np.dot(em1,em2)/(np.linalg.norm(em1)*np.linalg.norm(em2))\n",
    "    #Euclidean distance\n",
    "    #score = 1/(em1-em2).dot(em1-em2)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data from files\n",
    "trainingData = readData('training.txt')\n",
    "valid_pos = readData('val_positive.txt')\n",
    "valid_neg = readData('val_negative.txt')\n",
    "testData = readData('test.txt')\n",
    "validationData = valid_pos+valid_neg\n",
    "#build graph\n",
    "G = nx.read_edgelist('training.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = nx.betweenness_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate random walks\n",
    "walks = randomWalk(G,10,'bfs&dfs', B)\n",
    "#train model\n",
    "model = skipGram(walks, 'bfs&dfs')\n",
    "#compute proximity score\n",
    "linkScores={}\n",
    "for pair in validationData:\n",
    "    linkScores[pair[0]+' '+pair[1]] = computeProximityScore(model.wv[pair[0]],model.wv[pair[1]])\n",
    "top100Links = sorted(linkScores.items(), key=itemgetter(1))[::-1][:100]\n",
    "#validation & evaluation\n",
    "groundTruth={}.fromkeys([pair[0]+' '+pair[1] for pair in valid_pos])\n",
    "evaluation(top100Links,groundTruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adar_score(author1, author2, neighbors):\n",
    "    return sum([1.0/math.log(len(neighbors[v])) for v in neighbors[author1].intersection(neighbors[author2])])\n",
    "\n",
    "def getNeighbors(data):\n",
    "    neighbors = defaultdict(set)\n",
    "    for pair in data:\n",
    "        neighbors[pair[0]].add(pair[1])\n",
    "        neighbors[pair[1]].add(pair[0])\n",
    "    return neighbors\n",
    "\n",
    "neighbors = getNeighbors(trainingData)\n",
    "val_list = []\n",
    "for i in range(len(val_pos[0])):\n",
    "    val_list.append(tuple(val_pos[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ascore = {}\n",
    "for i in range(len(val_list)):\n",
    "    Ascore[val_list[i]] = adar_score(val_list[i][0], val_list[i][1], 'adar', neighbors)\n",
    "top_list = []\n",
    "for i in range(100):\n",
    "    max_score = max(Ascore, key=Ascore.get)\n",
    "    top_list.append(max_score)\n",
    "    Ascore.pop(max_score)\n",
    "evaluation(top_list, val_pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from igraph import *\n",
    "from math import *\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from random import shuffle\n",
    "from random import seed\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "import collections\n",
    "\n",
    "maxl = 2\n",
    "def katz_similarity(katzDict,i,j):\n",
    "\tl = 1\n",
    "\tneighbors = katzDict[i]\n",
    "\tscore = 0\n",
    "\n",
    "\twhile l <= maxl:\n",
    "\t\tnumberOfPaths = neighbors.count(j)\n",
    "\t\tif numberOfPaths > 0:\n",
    "\t\t\tscore += (beta**l)*numberOfPaths\n",
    "\n",
    "\t\tneighborsForNextLoop = []\n",
    "\t\tfor k in neighbors:\n",
    "\t\t\tneighborsForNextLoop += katzDict[k]\n",
    "\t\tneighbors = neighborsForNextLoop\n",
    "\t\tl += 1\n",
    "\n",
    "\treturn score\n",
    "\n",
    "def get_edge_list(dataset_path):\n",
    "\tdata_file = open(dataset_path)\n",
    "\tedge_list = map(lambda x:tuple(map(int,x.split())),data_file.read().split(\"\\n\")[:-1])\n",
    "\tdata_file.close()\n",
    "\treturn edge_list\n",
    "\n",
    "# Convert edge_list into a set of constituent edges\n",
    "def get_vertices_set(edge_list):\n",
    "\tres = set()\n",
    "\tfor x,y in edge_list:\n",
    "\t\tres.add(x)\n",
    "\t\tres.add(y)\n",
    "\treturn res\n",
    "\n",
    "# Calculates accuracy metrics (Precision & Recall),\n",
    "# for a given similarity-model against a test-graph.\n",
    "def print_precision_and_recall(sim,train_graph,test_graph,test_vertices_set,train_vertices_set):\n",
    "\tprecision = recall = c = 0\n",
    "\tfor i in test_vertices_set:\n",
    "\t\tif i in train_vertices_set:\n",
    "\t\t\tactual_friends_of_i = set(test_graph.neighbors(i))\n",
    "\n",
    "\t\t\t# Handles case where test-data < k\n",
    "\t\t\tif len(actual_friends_of_i) < k:\n",
    "\t\t\t\tk2 = len(actual_friends_of_i)\n",
    "\t\t\telse:\n",
    "\t\t\t\tk2 = k\n",
    "\n",
    "\t\t\ttop_k = set(get_top_k_recommendations(train_graph,sim,i,k2))\n",
    "\n",
    "\t\t\tprecision += len(top_k.intersection(actual_friends_of_i))/float(k2)\n",
    "\t\t\trecall += len(top_k.intersection(actual_friends_of_i))/float(len(actual_friends_of_i))\n",
    "\t\t\tc += 1\n",
    "\tprint('Precision is : ' + str(precision/c))\n",
    "\tprint('Recall is : ' + str(recall/c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KatzScore(u, v, G):\n",
    "    a = 1\n",
    "    neighbors = list(G.neighbors(u))\n",
    "    score = 0\n",
    "    while a <= 2:\n",
    "        numberofPath = neighbors.count(v)\n",
    "        if numberofPath > 0:\n",
    "            score += (0.05**a)*numberofPath\n",
    "        neighborsForNextLoop = []\n",
    "        for k in neighbors:\n",
    "            neighborsForNextLoop += list(G.neighbors(k))\n",
    "        neighbors = neighborsForNextLoop\n",
    "        a += 1\n",
    "    return score\n",
    "\n",
    "#read data from files\n",
    "trainingData = readData('training.txt')\n",
    "valid_pos = readData('val_positive.txt')\n",
    "valid_neg = readData('val_negative.txt')\n",
    "testData = readData('test.txt')\n",
    "validationData = valid_pos+valid_neg\n",
    "# Build graph\n",
    "train_graph = nx.read_edgelist('training.txt')\n",
    "\n",
    "# Katz score\n",
    "linkScores={}\n",
    "for pair in validationData:\n",
    "    linkScores[pair[0]+' '+pair[1]] = KatzScore(pair[0], pair[1], train_graph)\n",
    "top100Links = sorted(linkScores.items(), key=itemgetter(1))[::-1][:100]\n",
    "#validation & evaluation\n",
    "groundTruth={}.fromkeys([pair[0]+' '+pair[1] for pair in valid_pos])\n",
    "evaluation(top100Links,groundTruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "def KatzScore(u, v, G):\n",
    "    a = 1\n",
    "    neighbors = list(G.neighbors(u))\n",
    "    score = 0\n",
    "    while a <= 1:\n",
    "        numberofPath = neighbors.count(v)\n",
    "        if numberofPath > 0:\n",
    "            score += (0.05**a)*numberofPath\n",
    "        neighborsForNextLoop = []\n",
    "        for k in neighbors:\n",
    "            neighborsForNextLoop += list(G.neighbors(k))\n",
    "        neighbors = neighborsForNextLoop\n",
    "        a += 1\n",
    "    return score\n",
    "\n",
    "train = nx.read_edgelist('training.txt')\n",
    "valid_pos = nx.read_edgelist('val_positive.txt')\n",
    "valid_neg = nx.read_edgelist('val_negative.txt')\n",
    "test = nx.read_edgelist('test.txt')\n",
    "\n",
    "valid_all =[pair for pair in valid_pos.edges()] + [pair for pair in valid_neg.edges()] \n",
    "\n",
    "Katz = {}\n",
    "for pair in Valid_all:\n",
    "    Katz[pair[0] + ' ' + pair[1]] = KatzScore(pair[0], pair[1], train)\n",
    "    \n",
    "groundTruth={}.fromkeys([pair[0]+' '+pair[1] for pair in valid_pos.edges()])\n",
    "\n",
    "top100Links = sorted(Katz.items(), key = lambda d:d[1], reverse = True)[:100]\n",
    "count = 0\n",
    "for link in top100Links:\n",
    "    if link[0] in groundTruth:\n",
    "        count += 1\n",
    "count/len(groundTruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = get_edge_list('training.txt')\n",
    "test_list = get_edge_list('val_positive.txt')\n",
    "train_graph = Graph(train_list)\n",
    "test_graph = Graph(test_list)\n",
    "train_n = train_graph.vcount()\n",
    "#train_vertices_set = get_vertices_set(train_list) # Need this because we have to only consider target users who are present in this train_vertices_set\n",
    "#test_vertices_set = get_vertices_set(test_list) # Set of target users\n",
    "train_vertices_set = nx.read_edgelist('training.txt').nodes()\n",
    "test_vertices_set = nx.read_edgelist('valid_neg.txt').nodes()\n",
    "\n",
    "\n",
    "# build a special dict that is like an adjacency list\n",
    "katzDict = {}\n",
    "adjList = train_graph.get_adjlist()\n",
    "\n",
    "for i, l in enumerate(adjList):\n",
    "    katzDict[i] = l\n",
    "\n",
    "sim = [[0 for i in range(train_n)] for j in range(train_n)]\n",
    "for i in range(train_n):\n",
    "    #print(i)\n",
    "    if i not in train_vertices_set:\n",
    "        continue\n",
    "\n",
    "    for j in range(i+1, train_n):\n",
    "        if j in train_vertices_set:\t\t# TODO: check if we need this\n",
    "            sim[i][j] = sim[j][i] = katz_similarity(katzDict,i,j)\n",
    "\n",
    "print_precision_and_recall(sim,train_graph,test_graph,test_vertices_set,train_vertices_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {1,2}\n",
    "a.update({1,4})\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = nx.dfs_tree(G, '339')\n",
    "list(T.nodes())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for edge in list(nx.dfs_edges(G, '339')):\n",
    "    dfs.append(edge[1])\n",
    "dfs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(G.neighbors('339'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(iter(G['339']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfs_edges_(G, '8193')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs_edges_(G, source, reverse=False):\n",
    "    if reverse and isinstance(G, nx.DiGraph):\n",
    "        neighbors = G.predecessors_iter\n",
    "    else:\n",
    "        neighbors = G.neighbors_iter\n",
    "    print(neighbors)\n",
    "    visited = set([source])\n",
    "    queue = deque([(source, neighbors(source))])\n",
    "    while queue:\n",
    "        parent, children = queue[0]\n",
    "        print(children)\n",
    "        try:\n",
    "            child = next(children)\n",
    "            if child not in visited:\n",
    "                yield parent, child\n",
    "                visited.add(child)\n",
    "                queue.append((child, neighbors(child)))\n",
    "        except StopIteration:\n",
    "            queue.popleft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = '339'\n",
    "reverse = None\n",
    "if reverse and isinstance(G, nx.DiGraph):\n",
    "    neighbors = G.predecessors_iter\n",
    "else:\n",
    "    neighbors = G.neighbors\n",
    "visited = set([source])\n",
    "list(neighbors(source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = nx.bfs_tree(G, '339')\n",
    "list(T.nodes())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
